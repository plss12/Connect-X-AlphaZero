{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aff7727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from kaggle_environments import evaluate, make, utils\n",
    "import os\n",
    "import sys\n",
    "import inspect\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "from tianshou.algorithm.modelfree.dqn import DiscreteQLearningPolicy\n",
    "\n",
    "from Submissions.mcts_agent import mcts_agent\n",
    "from Submissions.minimax_agent import minimax_agent\n",
    "from Submissions.rainbow.rainbow_agent import rainbow_agent\n",
    "\n",
    "env = make(\"connectx\", debug=True)\n",
    "print(env.render(mode=\"ansi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37873b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random agent\n",
    "def random_agent(observation, configuration):\n",
    "    from random import choice\n",
    "    return choice([c for c in range(configuration.columns) if observation.board[c] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad0d6e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating agent against random and negamax\n",
    "def mean_reward(rewards, role):\n",
    "    if role == \"P1\":\n",
    "        return np.mean([r[0] for r in rewards])\n",
    "    else:\n",
    "        return np.mean([r[1] for r in rewards])\n",
    "\n",
    "def evaluate_agent(agent, num_episodes=10):\n",
    "    rewards_random_p1 = evaluate(\"connectx\", [agent, \"random\"], num_episodes=num_episodes)\n",
    "    rewards_random_p2 = evaluate(\"connectx\", [\"random\", agent], num_episodes=num_episodes)\n",
    "    rewards_negamax_p1 = evaluate(\"connectx\", [agent, \"negamax\"], num_episodes=num_episodes)\n",
    "    rewards_negamax_p2 = evaluate(\"connectx\", [\"negamax\", agent], num_episodes=num_episodes)\n",
    "\n",
    "    print(f\"Evaluating agent against random and negamax with {num_episodes} games as P1 and P2...\\n\")\n",
    "    \n",
    "    print(f\"P1 vs Random: {mean_reward(rewards_random_p1, 'P1')}\")\n",
    "    print(f\"P1 vs Negamax: {mean_reward(rewards_negamax_p1, 'P1')}\\n\")  \n",
    "\n",
    "    print(f\"P2 vs Random: {mean_reward(rewards_random_p2, 'P2')}\")\n",
    "    print(f\"P2 vs Negamax: {mean_reward(rewards_negamax_p2, 'P2')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469387f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging agent against random\n",
    "def debug_agent(agent):\n",
    "    env = make(\"connectx\", debug=True)\n",
    "    trainer = env.train([None, \"random\"])\n",
    "    observation = trainer.reset()\n",
    "\n",
    "    while not env.done:\n",
    "        t0 = time.time()\n",
    "        my_action = agent(observation, env.configuration)\n",
    "        t1 = time.time()\n",
    "        print(f\"Turn {observation.step + 1}: Action {my_action} (in {t1 - t0:.2f} seconds)\")\n",
    "        observation, reward, done, info = trainer.step(my_action)   \n",
    "\n",
    "    print(f\"\\nYou won :)\\n\" if env.state[0].reward > 0 else \"\\nYou lost :(\\n\")\n",
    "    print(env.render(mode=\"ansi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "360fd1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facing agents\n",
    "def facing_agents(agent_a, agent_b, num_episodes=10):\n",
    "    a_rewards = []\n",
    "    b_rewards = []\n",
    "\n",
    "    env = make(\"connectx\", debug=True)\n",
    "\n",
    "    for i in range(num_episodes):\n",
    "        if i < num_episodes // 2:\n",
    "            env.run([agent_a, agent_b])\n",
    "            a_rewards.append(env.state[0].reward)\n",
    "            b_rewards.append(env.state[1].reward)\n",
    "        else:\n",
    "            env.run([agent_b, agent_a])\n",
    "            b_rewards.append(env.state[0].reward)\n",
    "            a_rewards.append(env.state[1].reward)\n",
    "\n",
    "    print(f\"Agent A won {a_rewards.count(1)} times\")\n",
    "    print(f\"Agent B won {b_rewards.count(1)} times\")\n",
    "    print(f\"Draw {a_rewards.count(0)} times\")\n",
    "    return a_rewards, b_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104416d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'debug_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Debugging and evaluating Minimax\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdebug_agent\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegamax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m evaluate_agent(minimax_agent)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'debug_agent' is not defined"
     ]
    }
   ],
   "source": [
    "# Debugging and evaluating Minimax\n",
    "debug_agent(minimax_agent)\n",
    "evaluate_agent(minimax_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db86486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1: Action 3 (in 1.90 seconds)\n",
      "Turn 3: Action 3 (in 1.90 seconds)\n",
      "Turn 5: Action 5 (in 1.90 seconds)\n",
      "Turn 7: Action 3 (in 1.90 seconds)\n",
      "Turn 9: Action 3 (in 1.90 seconds)\n",
      "\n",
      "You won :)\n",
      "\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 0 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 1 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 1 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 0 | 1 | 0 | 1 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 2 | 2 | 2 | 1 | 0 | 2 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Debugging and evaluating MCTS\n",
    "debug_agent(mcts_agent)\n",
    "evaluate_agent(mcts_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc578bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1: Action 3 (in 0.00 seconds)\n",
      "Turn 3: Action 3 (in 0.00 seconds)\n",
      "Turn 5: Action 3 (in 0.00 seconds)\n",
      "Turn 7: Action 2 (in 0.00 seconds)\n",
      "Turn 9: Action 2 (in 0.00 seconds)\n",
      "Turn 11: Action 2 (in 0.00 seconds)\n",
      "Turn 13: Action 2 (in 0.00 seconds)\n",
      "\n",
      "You won :)\n",
      "\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 1 | 0 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 1 | 0 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 1 | 2 | 0 | 0 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 1 | 1 | 0 | 2 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 2 | 1 | 0 | 2 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "| 0 | 0 | 2 | 1 | 0 | 2 | 0 |\n",
      "+---+---+---+---+---+---+---+\n",
      "\n",
      "Evaluating agent against random and negamax with 10 games as P1 and P2...\n",
      "\n",
      "P1 vs Random: 1.0\n",
      "P1 vs Negamax: 0.4\n",
      "\n",
      "P2 vs Random: 1.0\n",
      "P2 vs Negamax: -0.3\n"
     ]
    }
   ],
   "source": [
    "# Debugging and evaluating Rainbow\n",
    "debug_agent(rainbow_agent)\n",
    "evaluate_agent(rainbow_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3e993a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Facing Minimax vs Rainbow_1\n",
      "Agent A won 10 times\n",
      "Agent B won 0 times\n",
      "Draw 0 times\n",
      "([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n",
      "\n",
      "Facing Minimax vs Rainbow_2\n",
      "Agent A won 10 times\n",
      "Agent B won 0 times\n",
      "Draw 0 times\n",
      "([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1])\n"
     ]
    }
   ],
   "source": [
    "# Facing different agents\n",
    "print(\"Facing MCTS vs Minimax\")\n",
    "res = facing_agents(mcts_agent, minimax_agent)\n",
    "print(res)\n",
    "\n",
    "print(\"\\nFacing MCTS vs Rainbow\")\n",
    "res = facing_agents(mcts_agent, rainbow_agent)\n",
    "print(res)\n",
    "\n",
    "print(\"\\nFacing Minimax vs Rainbow\")\n",
    "res = facing_agents(minimax_agent, rainbow_agent)\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ConnectX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
